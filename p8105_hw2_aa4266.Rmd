---
title: "P8105 HW2"
author: "Abhishek Ajay (aa4266)"
date: "October 1, 2018"
output: 
  github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(p8105.datasets)
library(ggplot2)
```
 
#Problem 1

##Data import and manipulation

```{r p1_data_import}
nyc_transit_data = 
  read_csv("./datasets/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```
The dataset at hand contains information related to each entrance and exit for *each* subway station in New York City. 

The variables in the original dataset are Division, Line, Station Name, Station Latitute and Longitude, Route names of Route numbers 1 to 11, each station's Entrace Type, whether they have an entry or not, whether they're Exit only or not, whether they have Vending, Staffing scenario (NONE, FULL, PART), Staff hours, ADA Complaince, some notes regarding ADA, availability of Free Crossover, the station's North South Street and East West Street, the station's Corner, Entrance Latitude, Longitude, Station Location, Entrance Location. 

The data has been imported and cleaned by cleaning the column names into to standard, single format (underscore), selection of specific columns such as all columns from line to entry and vending and ADA compliance data, that are relevant for further analysis. The cell data of the entry column has been converted from character YES/NO into logical TRUE and FALSE. 

The dimensions of the new table is `r dim(nyc_transit_data)`

No, the data isn't tidy. The columns are redundant with columns for each route number. 

##Further Questions on this data:

###Question 1

How many distinct stations are there?

There are `r count(distinct(nyc_transit_data, line, station_name))`

###Question 2

How many stations are ADA compliant?

```{r p1_q2}
print(
  paste(
    "There are",
    nyc_transit_data %>% 
      filter(ada == TRUE) %>% 
      distinct(line, station_name) %>% 
      count(),
    "stations that are ADA complaint"
  )
)
```

###Question 3

What proportion of station entrances / exits without vending allow entrance?

```{r p1_q3}
print(
  paste(
    "The proportion of stations entrances/exits without vending that allow entrance are",
    nyc_transit_data %>%
      filter(vending == "NO", entry == TRUE) %>%
      count()/nrow(nyc_transit_data[which(nyc_transit_data$vending == "NO"),])
  )
) 
```

###Reformatting of the data

Here we reformat the data such the route number and the route name are distinct variables.

```{r p1_reformatting}
nyc_transit_data_reformatting =
  nyc_transit_data %>%
  gather(key = route_number, value = route_name, route1:route11) %>%
  separate(route_number, into = c("route_str", "route_number"), sep = 5) %>%
  select(-route_str)
```

##Further questions on the reformatted table

###Question 1 

How many distinct stations serve the A train?

```{r p1_reformatting_q1}
print(
  paste(
    "The number of distinct stations serving the A train:",
    nyc_transit_data_reformatting %>%
      filter(route_name == "A") %>%
      distinct(line, station_name) %>%
      count()
  )
) 
```

###Question 2

Of the stations that serve the A train, how many are ADA compliant?

```{r p1_reformatting_q2}
print(paste(
  "ADA complaint stations that serve the A train:",
  nyc_transit_data_reformatting %>%
    filter(route_name == "A", ada == TRUE) %>%
    distinct(line, station_name) %>%
    count()
  )
)
```

#Problem 2

Import and manipulation of the Mr. Trash Wheel Dataset.

```{r p2_data_import}
mr_trash_wheel_data =
  read_excel("./datasets/HealthyHarborWaterWheelTotals2018-7-28.xlsx", range = "A2:N338") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = as.integer(round(sports_balls))) %>% 
  rename("weight" = weight_tons, "volume" = volume_cubic_yards)
```

Import and manipulation of the precipitation data from 2016 and 2017

```{r p2_data_import_precip}
trash_wheel_precip_data_2016 =
  read_excel("./datasets/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, range = "A2:B15") %>% 
  janitor::clean_names() %>%
  filter(!is.na(total)) %>%
  select(month, total_precipitation = total)

trash_wheel_precip_data_2016$year = 2016


trash_wheel_precip_data_2017 =
  read_excel("./datasets/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, range = "A2:B15") %>% 
  janitor::clean_names() %>%
  filter(!is.na(total)) %>%
  select(month, total_precipitation = total)

trash_wheel_precip_data_2017$year = 2017
```

Combining the the precipitation data tables fromm both 2016 and 2017.

```{r p2_precip_combining}
trash_wheel_precip_data_2016_2017 =
  left_join(trash_wheel_precip_data_2016, trash_wheel_precip_data_2017, by = 'month') %>% 
  mutate(month = month.name[month])

trash_wheel_precip_data_2016_2017$month[13] = "Grand Total"
```


##Write some stuff about probl
Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

##Data Description

The data used here is from the *Mr. Trash Wheel* dataset taken from the course website, P8105.com which is in the excel format. However, it is openly available on Baltimore Waterfront website under the *Trash Wheel Project*. The project was initiated in 2014.

We get the precipitaion data for years 2016 and 2017 from sheets 5 and 4 of the excel respectively. We added an extra variable to both the tables for year. The dimensions of both the datasets are `r dim(trash_wheel_precip_data_2016)`. 

Number of observations for each year 2016 and 2017 precipitation dataset is `r count(trash_wheel_precip_data_2016_2017[which(trash_wheel_precip_data_2016_2017$month != "Grand Total"),])`.

Number of observations that are dumper sepcific is `r nrow(mr_trash_wheel_data)`.

Total homes powered since May 2014 up till July 2018 is `r iohoivnorh`.

It is observed that among those rows which had no comments, the most accummulated trash is `r head((sort(colSums(select(mr_trash_wheel_data, plastic_bottles:sports_balls)), decreasing = TRUE)), 1)`


Using the points mentioned on http://korbedpsych.com/R02Variables.html:

* Key variables for the Mr. Trash Wheel sheet of the Mr. Trash Wheel dataset are: 
  
    * dumpster
  
    * year
  
    * weight
  
    * volume
    
    * homes_powered
  
* Key Variables for the combined precipitation dataset for 2016 and 2017 are: 
    
    * month
  
    * total_precipitation
  
    * year



#Problem 3

Here we use the BRFSS data set from the P8105.datasets package and format it.
```{r p3_data_impot_format}
#View(p8105.datasets::brfss_smart2010)

brfss_dataset =
  p8105.datasets::brfss_smart2010 %>%
  janitor::clean_names() %>% 
  rename(resp_id = respid, location_abbreviation = locationabbr, location_desc = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  select(-c(class:question), -sample_size, -c(confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(excellent_or_very_good = excellent + very_good)
```

##Further questions on brfss_dataset

###Question 1

How many unique locations are included in the dataset? Is every state represented? What state is observed the most?

```{r p3_q1}
#Used the cat function to integrate the line break since it doesn't work with print
cat(
  paste(
    "Number of unique locations included in the dataset:",
    brfss_dataset %>% 
      distinct(location_abbreviation) %>% 
      count(),
    "\n\nAll 50 states and 1 US Territory, the District of Columbia, are represent in the dataset table"
  )
)
```

```{r p3_q1_mode}
print(
  paste(
    "The most observed state in the table is:",
    brfss_dataset %>% 
      select(location_abbreviation) %>% 
      table() %>% 
      sort() %>% 
      names() %>% 
      tail(1)
  )
)
```

```{r p3_q2_q3}
excellent_2002 =
  brfss_dataset %>% 
  filter(year == 2002) %>%
  select(excellent) 
```

###Question 2

In 2002, what is the median of the “Excellent” response value?
The median of the "Excellent" response value in 2002 is `r median(excellent_2002$excellent, na.rm = TRUE)`. 

###Question 3

Make a histogram of “Excellent” response values in the year 2002.

```{r p3_q3_plot} 
hist(excellent_2002$excellent, main = "Histogram of \"Excellent\" response values in 2002", xlab = "excellent values" )
```

###Question 4

Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r p3_q4}
brfss_dataset %>% 
  filter(location_desc == "NY - New York County" | location_desc == "NY - Queens County") %>%
  ggplot(aes(x = year, y = excellent )) + geom_point(aes(color = location_desc))
```